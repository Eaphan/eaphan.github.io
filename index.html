<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yifan Zhang</title>
  
  <meta name="author" content="Yifan Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="images/z_icon.png" type="image/x-icon" / >
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yifan Zhang</name>
              </p>
              <p>I am a final year Ph.D. candidate at <a href="https://www.cs.cityu.edu.hk/">CityUHK</a>, working with <a href="https://sites.google.com/site/junhuihoushomepage/">Prof. HOU Junhui</a>. Before that, I served as an research engineer at Baidu. I received B.E. degree at Huazhong University of Science and Technology and M.S. degree at Shanghai Jiao Tong University. My current research mainly focuses on the 3D perception within the context of autonomous driving.
              </p>
              <!-- <p>
                More description.
              </p> -->
              <p style="text-align:center">
                <a href="mailto:yfzhang25@gmail.com">Email</a> &nbsp/&nbsp
                <!-- <a href="data/CV.pdf">CV (TODO)</a> &nbsp/&nbsp -->
                <a href="https://github.com/Eaphan/">Github</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=FyLl6J0AAAAJ&hl=zh-CN">Scholar</a> &nbsp/&nbsp
                <a href="https://x.com/YifanTweets">Twitter</a> &nbsp/&nbsp
                <!-- <a href="https://www.linkedin.com/in/%E5%BC%82%E5%87%A1-%E5%BC%A0-15062090">LinkedIn</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/yifan_zhang.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/yifan_zhang_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:5px;width:100%;vertical-align:middle">
              <heading>Recent Projects</heading> <br>(*: Co-author, #: Corresponding Author)
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:5px;width:30%;vertical-align:middle">
                <img src='images/2024_OLIVINE.png' width="220">
            </td>
            <td style="padding:5px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2405.14271">
                <papertitle>Fine-grained Image-to-LiDAR Contrastive Distillation with Visual Foundation Models</papertitle>
              </a>
              <br>
              <strong>Yifan Zhang</strong>, Junhui Hou
              <br>
              <em>Arxiv</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2405.14271">paper</a> /
              <a href="https://github.com/Eaphan/OLIVINE">code</a>
            </td>
          </tr>
          <tr><td><br></td></tr>

          <tr>
            <td style="padding:5px;width:30%;vertical-align:middle">
                <img src='images/2024_NCLR.png' width="220">
            </td>
            <td style="padding:5px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2401.12452">
                <papertitle>Self-supervised Learning of LiDAR 3D Point Clouds via 2D-3D Neural Calibration</papertitle>
              </a>
              <br>
              <strong>Yifan Zhang</strong>, Siyu Ren, Junhui Hou, Jinjian Wu, Yixuan Yuan, Guangming Shi
              <br>
              <em>Arxiv</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2401.12452">paper</a> /
              <a href="https://github.com/Eaphan/NCLR">code</a>
            </td>
          </tr>
          <tr><td><br></td></tr>

          <tr>
            <td style="padding:5px;width:30%;vertical-align:middle">
                <img src='images/2024_STEMD.png' width="220">
            </td>
            <td style="padding:5px;width:70%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/10636791/">
                <papertitle>Spatial-Temporal Graph Enhanced DETR Towards Multi-Frame 3D Object Detection</papertitle>
              </a>
              <br>
              <strong>Yifan Zhang</strong>, Zhiyu Zhu, Junhui Hou, Dapeng Wu
              <br>
              <em>TPAMI</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2307.00347">paper</a> /
              <a href="https://github.com/Eaphan/STEMD">code</a>
              <!-- <p>
                Introduction to paper.
              </p> -->
            </td>
          </tr>
          <tr><td><br></td></tr>

          <tr>
            <td style="padding:5px;width:30%;vertical-align:middle">
                <img src='images/2024_EventSAM.png' width="220">
            </td>
            <td style="padding:5px;width:70%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Segment_Any_Event_Streams_via_Weighted_Adaptation_of_Pivotal_Tokens_CVPR_2024_paper.html">
                <papertitle>Segment Any Event Streams via Weighted Adaptation of Pivotal Tokens</papertitle>
              </a>
              <br>
              Zhiwen Chen, Zhiyu Zhu, <strong>Yifan Zhang</strong>, Junhui Hou, Guangming Shi, Jinjian Wu
              <br>
              <em>CVPR</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2312.16222">paper</a> /
              <a href="https://github.com/zhiwen-xdu/EventSAM">code</a>
            </td>
          </tr>
          <tr><td><br></td></tr>

          <tr>
            <td style="padding:5px;width:30%;vertical-align:middle">
                <img src='images/2024_Robust3DOD.jpg' width="220">
            </td>
            <td style="padding:5px;width:70%;vertical-align:middle">
              <a href="https://link.springer.com/article/10.1007/s11263-023-01934-3/">
                <papertitle>A Comprehensive Study of the Robustness for LiDAR-Based 3D Object Detectors Against Adversarial Attacks</papertitle>
              </a>
              <br>
              <strong>Yifan Zhang</strong>, Yixuan Yuan, Junhui Hou
              <br>
              <em>IJCV</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2212.10230">paper</a> /
              <a href="https://github.com/Eaphan/Robust3DOD">code</a>
            </td>
          </tr>
          <tr><td><br></td></tr>

          <tr>
            <td style="padding:5px;width:30%;vertical-align:middle">
                <img src='images/2023_UPIDet.png' width="220">
            </td>
            <td style="padding:5px;width:70%;vertical-align:middle">
              <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/a1f0c0cd6caaa4863af5f12608edf63e-Abstract-Conference.html">
                <papertitle>Unleash the Potential of Image Branch for Cross-modal 3D Object Detection</papertitle>
              </a>
              <br>
              <strong>Yifan Zhang</strong>, Qijian Zhang, Junhui Hou, Yixuan Yuan, Guoliang Xing
              <br>
              <em>NeurIPS</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2301.09077">paper</a> /
              <a href="https://github.com/Eaphan/UPIDet">code</a>
            </td>
          </tr>
          <tr><td><br></td></tr>

          <tr>
            <td style="padding:5px;width:30%;vertical-align:middle">
                <img src='images/2023_GLENet.jpg' width="220">
            </td>
            <td style="padding:5px;width:70%;vertical-align:middle">
              <a href="https://link.springer.com/article/10.1007/s11263-023-01869-9">
                <papertitle>GLENet: Boosting 3D Object Detectors with Generative Label Uncertainty Estimation</papertitle>
              </a>
              <br>
              <strong>Yifan Zhang</strong>, Qijian Zhang, Zhiyu Zhu, Junhui Hou, Yixuan Yuan
              <br>
              <em>IJCV</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2207.02466">paper</a> /
              <a href="https://github.com/Eaphan/GLENet">code</a>
            </td>
          </tr>
          <br>
        </tbody></table>
        <!-- paper done -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:0px;text-align:center;width:100%;">
                <br>
                <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=MocJBuU8nUOktSRjiCg3rHl2bPphHgs9-zc8eeJzojg'></script>
                Source code credit to <a href="https://jonbarron.info/" target="_blank">Dr. Jon Barron</a>
              </td>
            </tr>
          </tbody>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>